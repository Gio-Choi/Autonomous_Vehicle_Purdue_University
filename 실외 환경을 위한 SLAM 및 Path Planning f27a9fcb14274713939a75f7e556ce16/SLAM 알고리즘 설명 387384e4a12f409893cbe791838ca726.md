# SLAM Algorithm Explanation

We conducted various experiments to find SLAM methods and sensors that work robustly even in outdoor environments.

![Screen Shot 2022-08-24 at 12.23.45 PM.png](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screen_Shot_2022-08-24_at_12.23.45_PM.png)

![Depth Camera (Intel Realsense)](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screen_Shot_2022-08-24_at_10.41.17_AM.png)

Depth Camera (Intel Realsense)

![2D LiDAR (YDLiDAR X4)](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screenshot_2022-11-13_at_12.50.40_PM.png)

2D LiDAR (YDLiDAR X4)

As a result, we decided to improve the ORB-SLAM2 algorithm using a monocular camera by incorporating GPS data.

### ORB-SLAM2

ORB-SLAM2 consists of three stages:

1. **Camera Tracking**  
   In this stage, the system extracts Map points from frames to estimate the vehicle's pose. By comparing the Map points extracted from consecutive frames, the system identifies KeyFrames, which represent significant locations.
   
2. **Local Mapping**  
   In this stage, the cameraâ€™s pose is optimized within the constructed map (Local Map). By adding newly extracted KeyFrames to the Local Map, the map is expanded.
   
3. **Loop Closing**  
   When the vehicle revisits a previously visited location, the system detects this and corrects accumulated errors. ORB-SLAM2 performs this process using the Covisibility Graph.

## Algorithm Improvement Process

### Tracking Stage

![Untitled](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Untitled.png)

We used GPS data when it was difficult to accurately measure the vehicle's movement based on odometry values alone, due to factors such as slopes, road unevenness, and mud.

We reduced computation by ensuring that the subsequent processes only proceed **after the vehicle has moved a certain distance**.

Additionally, by comparing candidate KeyFrame values based on GPS data, we prevented the generation of unnecessary KeyFrames.

### Local Mapping Stage

![Screenshot 2022-11-13 at 1.06.14 PM.png](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screenshot_2022-11-13_at_1.06.14_PM.png)

In this stage, we improved accuracy by incorporating GPS data into the weight calculations when constructing the Covisibility graph.
